# Gu√≠a de Uso de Modelos Guardados

Este documento explica c√≥mo usar los modelos de machine learning entrenados y guardados para hacer predicciones.

## üìÅ Estructura de Archivos

Despu√©s de ejecutar `train.py`, se crear√° un directorio `models/` con los siguientes archivos:

```
models/
‚îú‚îÄ‚îÄ regresion_lineal.pkl              # Modelo de Regresi√≥n Lineal
‚îú‚îÄ‚îÄ bosques_aleatorios.pkl            # Modelo de Bosques Aleatorios
‚îú‚îÄ‚îÄ regresion_de_vectores_de_soporte.pkl  # Modelo SVR
‚îú‚îÄ‚îÄ potenciacion_de_gradiente.pkl     # Modelo de Gradient Boosting
‚îú‚îÄ‚îÄ best_model.pkl                    # El mejor modelo (copia del mejor)
‚îú‚îÄ‚îÄ standard_scaler.pkl               # StandardScaler para normalizaci√≥n
‚îú‚îÄ‚îÄ label_encoders.pkl                # LabelEncoders para variables categ√≥ricas
‚îî‚îÄ‚îÄ column_info.pkl                   # Informaci√≥n de columnas y estructura
```

## üöÄ Uso R√°pido

### 1. Cargar Modelos

```python
from load_models import load_models_and_scalers

# Cargar todos los modelos y scalers
models_dict = load_models_and_scalers()

# Acceder a componentes espec√≠ficos
models = models_dict['models']           # Todos los modelos
best_model = models_dict['best_model']   # El mejor modelo
scaler = models_dict['scaler']           # StandardScaler
label_encoders = models_dict['label_encoders']  # LabelEncoders
column_info = models_dict['column_info'] # Informaci√≥n de columnas
```

### 2. Preprocesar Nuevos Datos

```python
from load_models import preprocess_new_data

# Supongamos que tienes nuevos datos
new_data = pd.DataFrame({
    'COLEGIO_ANIO_EGRESO': [2023],
    'ANIO_POSTULA': [2024],
    'CICLO_POSTULA': [1],
    'ANIO_NACIMIENTO': [1995],
    'CALIF_FINAL': [15.5],
    'COLEGIO': ['LA DIVINA PROVIDENCIA'],
    'ESPECIALIDAD': ['INGENIER√çA DE SISTEMAS'],
    'SEXO': ['MASCULINO'],
    'MODALIDAD': ['ORDINARIO'],
    'INGRESO': ['SI']
})

# Preprocesar los datos
processed_data = preprocess_new_data(
    new_data, 
    models_dict['label_encoders'], 
    models_dict['scaler'], 
    models_dict['column_info']
)
```

### 3. Hacer Predicciones

```python
from load_models import predict_with_models

# Predicciones con todos los modelos
predictions = predict_with_models(processed_data, models_dict)

# O usar un modelo espec√≠fico
best_model = models_dict['best_model']
prediction = best_model.predict(processed_data)
```

## üìä Ejemplos de Uso

### Ejemplo Completo
Ejecuta el archivo `example_prediction.py` para ver un ejemplo completo:

```bash
python example_prediction.py
```

### Ejemplo R√°pido
Para el uso m√°s simple, ejecuta `quick_start.py`:

```bash
python quick_start.py
```

```bash
python example_prediction.py
```

Este script demuestra:
- Carga de modelos
- Creaci√≥n de datos de ejemplo
- Preprocesamiento
- Predicciones con todos los modelos
- An√°lisis de resultados

## üîß Funciones Disponibles

### `load_models_and_scalers()`
Carga todos los modelos y componentes de preprocesamiento guardados.

**Retorna:** Diccionario con:
- `models`: Todos los modelos entrenados
- `best_model`: El mejor modelo
- `scaler`: StandardScaler
- `label_encoders`: LabelEncoders para variables categ√≥ricas
- `column_info`: Informaci√≥n de estructura de datos

### `preprocess_new_data(data, label_encoders, scaler, column_info)`
Preprocesa nuevos datos usando los encoders y scaler guardados.

**Par√°metros:**
- `data`: DataFrame con nuevos datos
- `label_encoders`: LabelEncoders cargados
- `scaler`: StandardScaler cargado
- `column_info`: Informaci√≥n de columnas

**Retorna:** Array numpy con datos preprocesados

### `predict_with_models(new_data, models_dict)`
Realiza predicciones con todos los modelos cargados.

**Par√°metros:**
- `new_data`: Datos preprocesados
- `models_dict`: Diccionario con modelos cargados

**Retorna:** Diccionario con predicciones de cada modelo

## üìã Requisitos de Datos

Los nuevos datos deben tener las siguientes columnas:

### Columnas Categ√≥ricas:
- `COLEGIO`: Nombre del colegio
- `ESPECIALIDAD`: Especialidad de estudio
- `SEXO`: G√©nero (MASCULINO/FEMENINO)
- `MODALIDAD`: Modalidad de ingreso (ORDINARIO, etc.)
- `INGRESO`: Estado de ingreso (SI/NO)

### Columnas Num√©ricas:
- `COLEGIO_ANIO_EGRESO`: A√±o de egreso del colegio
- `ANIO_POSTULA`: A√±o de postulaci√≥n
- `CICLO_POSTULA`: Ciclo de postulaci√≥n
- `ANIO_NACIMIENTO`: A√±o de nacimiento
- `CALIF_FINAL`: Calificaci√≥n final (caracter√≠stica m√°s importante)

## ‚ö†Ô∏è Notas Importantes

1. **Formato de Datos**: Los nuevos datos deben tener exactamente las mismas columnas que se usaron durante el entrenamiento.

2. **Valores Categ√≥ricos**: Los valores en las columnas categ√≥ricas deben estar dentro del rango de valores vistos durante el entrenamiento.

3. **Escalado**: Algunos modelos (Regresi√≥n Lineal, SVR) usan datos escalados, mientras que otros (Bosques Aleatorios, Gradient Boosting) no.

4. **Predicciones**: Las predicciones son valores continuos entre 0 y 1. Para clasificaci√≥n binaria, usa un umbral de 0.5.

## üõ†Ô∏è Soluci√≥n de Problemas

### Error: "El directorio 'models' no existe"
- Ejecuta `train.py` primero para entrenar y guardar los modelos.

### Error: "ValueError: Found input variables with inconsistent numbers of features"
- Verifica que los nuevos datos tengan las mismas columnas que se usaron durante el entrenamiento.

### Error: "ValueError: y contains previously unseen labels"
- Los valores categ√≥ricos en los nuevos datos deben estar dentro del rango de valores del entrenamiento.

## üìà Interpretaci√≥n de Resultados

- **Predicci√≥n > 0.5**: Probable INGRESO
- **Predicci√≥n ‚â§ 0.5**: Probable NO INGRESO
- **Valor m√°s alto**: Mayor probabilidad de ingreso
- **Valor m√°s bajo**: Menor probabilidad de ingreso

## üîÑ Actualizaci√≥n de Modelos

Para actualizar los modelos con nuevos datos:
1. Agrega los nuevos datos al dataset original
2. Ejecuta `train.py` nuevamente
3. Los modelos se sobrescribir√°n autom√°ticamente 